# Machinehack_Intel_oneapi_hackathon_the_llm_challenge


### Competition hosted on <a href="https://machinehack.com/hackathons/intel_oneapi_hackathon_the_llm_challenge/overview">Machinehack</a>

# About

### Generate a response for the question from pre-defined text using LLM(Extracted Question-Answering(QA) Model).

### The Final Competition score is 0.25114

### Final Leaderboard Rank is 9/35

### The Evaluation Metric is Accuracy.

### File information
 
 * mh-intel-oneapi-hackathon-the-llm-challenge-eda.ipynb [![Open in Kaggle](https://img.shields.io/static/v1?label=&message=Open%20in%20Kaggle&labelColor=grey&color=blue&logo=kaggle)](https://www.kaggle.com/code/hari141v/mh-intel-oneapi-hackathon-the-llm-challenge-eda)
    #### Basic Exploratory Data Analysis
    #### Packages Used,
        * seaborn 
        * Pandas
        * Numpy
        * Matplotlib
        * nltk
        * spacy
        * wordcloud
        * spellchecker
        * sklearn

* mh-intel-oneapi-hackathon-the-llm-challenge-model.ipynb [![Open in Kaggle](https://img.shields.io/static/v1?label=&message=Open%20in%20Kaggle&labelColor=grey&color=blue&logo=kaggle)](https://www.kaggle.com/code/hari141v/mh-intel-oneapi-hackathon-the-llm-challenge-model2)
    #### I have directly used a pre-trained model without fine-tuning it on the training data, primarily due to my limited knowledge of NLP-QA tasks. I loaded and predicted the test data using the transformers inference pipeline.
    #### Packages Used, 
        * Pandas
        * Huggingface
        
  

